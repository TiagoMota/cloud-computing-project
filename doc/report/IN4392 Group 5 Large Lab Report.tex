\documentclass[a4paper]{IEEEtran}

\usepackage[fleqn]{amsmath}
%\usepackage{amsfonts}
%\usepackage{algorithm}% http://ctan.org/pkg/algorithms
%\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{hyperref}
%\usepackage{verbatim}
%\usepackage{textcomp}
\usepackage{pdflscape}

\usepackage{graphicx}
\graphicspath{ {images/} }

\title{CloudOCR: Cloud Computing Large Lab Assignment}
\author{Tiago Mota, Eddy Bertoluzzo, David Hoepelman}

\begin{document}

\maketitle

\begin{abstract}

Blah
\end{abstract}

\section{Introduction}


\subsection{Problem}
WantCloud BV with the providing of facilities to run OCR jobs on Tesseract-OCR\footnote{An OCR Engine that was developed at HP Labs between 1985 and 1995... and now at Google.} have been assuring a great amount of financial income and also a preoccupying increase of this service popularity. Since there is only one machine to execute all the jobs submitted by all the users, WantCloud BV verified that most of the system is no longer capable of guaranteeing the job deadlines for all the users, violating it's own Terms-of-Use. They though that is necessary to improve the limitations of one single machine running Tesseract by using a IaaS platform to run multiple instances of the program.

\subsection{Proposed solution}
Using Amazon Web Services as the cloud infrastructure provider, we present CloudOCR, a system capable of OCR an entire digitalized library of papers, returning the output in simple plain text. The system have to guarantee scaling during peak usage and load-balance the across the multiple machines, so to effectively do this, CloudOCR monitors the working machines or instances (hereby called workers) to keep track of the system current load and the need to allocating or deallocating a worker. Also, all the jobs are scheduled to the workers in a way that a minimal workload balance can be maintained.

\subsection{Report structure}
The next section refers to a detailed system design to fully understand the system components, followed by all the experiments and their respective setups. The final two sections of this document will correspond to the results discussion and conclusions.


\section{Background on Application}
CloudOCR is based on a previous working technology called Tesseract-OCR, that provides an OCR engine for images files like ``.jpg'' and ``.png'', turning them into simple text files. Our application takes ``.jpg'' image files as input and output a simple ``.txt'' text file, using EC2 instances and spot instances leased to the Amazon Web Services. Users upload a image file (equivalent to one job) through a simple online front-end which in turn stores the file as a Job in the CloudOCR database. Afterwards, the scheduler will query the database for unassigned jobs and split them among the available workers. At the same time, there is a monitor controlling the system resource usage that provides information to the allocator manager, responsible to allocate and deallocate workers through time, according to the system needs. After a worker finish a job, the output is sent to a user desired storage location.
To be able to implement the WantedCloud BV's successor to the Tesseract service, there are few requirements that need to be addressed:
\begin{itemize}
	\item Automation
	\item Elasticity
	\item Performance
	\item Reliability
	\item Monitoring
\end{itemize}
The next section introduces the system design of CloudOCR and also, explain how did we meet the above requirements.

\section{System Design}

\subsection*{Global overview}
CloudOCR is composed by a master server and working Virtual Machines (hereby VM's only). The master server is the one responsible for all management operations of the system, such as job  scheduling, resource allocation, fault management and so on. The jobs are distributed among the VM's. These are spot instances: impossible to know how long it will take for a new spot instance to be available, but the cost is much lower.
To show the system design, a high-level diagram can be found in Figure \ref{fig_sysarch}.
Our system components are:

\begin{LaTeXdescription}

\item[Front-End]
The online front-end interface where jobs can be submitted by users, and a priority can be assigned. By using a simple Java program, the new jobs are stored on the system database.

\item[Job Queue]
The job queue holds jobs that still need to be processed and meta-information like priority and number of failures. We implemented it using a MySQL database, querying it to get the updated, sorted by priority, job queue.

\item[Job Scheduler]
The scheduler assigns the jobs present on the queue to the available workers and includes the logic for \textbf{load-balancing}. A \textbf{greedy on-line load-balancing} algorithm \cite{kleinberg2006} is used to assign these jobs to those workers, until a predefined maximum amount of jobs per worker is reached and the scheduler is executed at regular predefined intervals.
These predefined values change according to the system policy applied to the CloudOCR application.

\item[Workers]
A worker exits only to execute its jobs. They are implemented as Amazon EC2 instances running a common AMI that has the open source OCR engine installed, Tesseract-OCR.

\item[System Monitor]
The system monitor keeps track of useful information like job status or resource usage, in order to provide this information to other system components like the fault or allocation manager.

\item[Fault Manager]
The fault manager waits for the monitor's fault information and handle it accordingly, which means a failed job is resubmitted to the job queue and failing VM's are shutdown (if not already). A job that consistently fails for a predefined amount of times is logged, instead of resubmitted.

\item[Allocation Manager]
The allocation manager waits for the monitor's resource usage information and new ones are allocated or old ones removed. New spot instances are allocated based on current submitted jobs and when the price is low enough.

\end{LaTeXdescription}

\subsection*{Resource management}

\begin{LaTeXdescription}
\item[Automation]
Almost all of the implemented system is automated, except when submitting new jobs and when dealing with faulty ones, where the job is deleted from the queue.

\item[Elasticity]
The \textbf{Allocation Manager} handle all the new resources (instances) allocation an deallocation, providing an automatic scaling to the system. The master itself is never scaled.

\item[Performance]
The \textbf{Job Scheduler} is responsible for guaranteeing the system load balance.

\item[Reliability]
The system uses a master-slave architecture where the master contains all of the management operations, while the slaves (workers) process jobs. Reliability for the workers and jobs is provided by the \textbf{Fault Manager}, which handle all the failures in VM's and its jobs. For the master, there is no reliability provided

\item[Monitoring]
A dedicated monitoring subsystem keep track of the workers and aggregates information for other components to use and can also be logged if necessary.

\end{LaTeXdescription}

\subsection*{System Policies}

\begin{LaTeXdescription}

\item[Job Allocation]
Users can specify a priority to a job, which means that jobs will only be chosen by the scheduler when no higher-priority jobs are available. In order to prevent starvation, jobs with the same priority are scheduled according to time they were submitted, which means first in, first out.

\item[Resource Allocation]
A configurable minimum throughput is maintained and there is no upper limit on allocated resources. If there are enough jobs available and the price of spot instances is low enough, a new instance is allocated.

\end{LaTeXdescription}

\subsection*{Additional System Features}

\begin{LaTeXdescription}
\item[Scheduling]
Our solution focus on efficient scheduling to minimize the total cost. This is done by the Allocation Manager, using spot instances to keep the price as low as possible, while maintaining a configurable minimal throughput.
The user can also configure this price/performance trade-off.

\end{LaTeXdescription}

\section{Experimantal results}

\subsection{Setup}

We used Amazon EC2 m1.micro, m1.small and m1.medium instances in all our tests. Specifications can be found in table \ref{amazoninstancespec}

\begin{table}
\centering
\begin{tabular}{| l | l | l | l |}
Type & CPU (ECU\footnote{One EC2 Compute Unit (ECU) provides the equivalent CPU capacity of a 1.0-1.2 GHz 2007 Opteron or 2007 Xeon processor.}) & a\\ \hline
\end{tabular}
\caption{Amazon EC2 instance types}
\label{amazoninstancespec}
\end{table}

\subsection{Database performance}

\subsection{Instance type selection}

\subsection{Allocation behavior}

\section{Discussion}

\section{Conclusion}

\begin{thebibliography}{9}

\bibitem{kleinberg2006}{
 Algorithm design: Chapter 11, \emph{Kleinberg, Jon and Tardos, Ã‰va}, Pearson/Addison Wesley, Boston (Mass.), ISBN: 0-321-37291-3
 }
\end{thebibliography}

\appendix{Time spent}

\newpage

\begin{landscape}
\appendix

\begin{figure}[h]
\centering
\includegraphics[width=770pt]{"System Architecture 2"}
\caption{System architecture}
\label{fig_sysarch}
\end{figure}
\end{landscape}
\clearpage

\end{document}